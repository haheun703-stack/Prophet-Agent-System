# -*- coding: utf-8 -*-
"""
ì´ìƒê±°ë˜ ê°ì§€ê¸° â€” Volume Spike Scanner
========================================
+30% í­ë“± 1~3ì¼ ì „ ë‚˜íƒ€ë‚˜ëŠ” ì´ìƒ ê±°ë˜ëŸ‰ íŒ¨í„´ 5ì¢…ì„ ê°ì§€í•œë‹¤.

íŒ¨í„´:
  1. VOLUME_SPIKE      â€” ê±°ë˜ëŸ‰ 2.5ë°° ì´ìƒ ê¸‰ì¦
  2. QUIET_ACCUMULATION â€” ê±°ë˜ëŸ‰ 3ë°°+ ì¸ë° ê°€ê²©ë³€ë™ 3% ë¯¸ë§Œ (ì¡°ìš©í•œ ë§¤ì§‘)
  3. OBV_BREAKOUT      â€” OBV ì‹ ê³ ê°€ but ì£¼ê°€ëŠ” ì•„ë‹˜ (ëˆì´ ë¨¼ì € ë“¤ì–´ì˜´)
  4. MULTI_DAY_ACCUM   â€” 3ì¼ ì—°ì† ê±°ë˜ëŸ‰ ì¦ê°€ + ì£¼ê°€ ìƒìŠ¹
  5. BIG_MONEY_INFLOW  â€” ê±°ë˜ëŒ€ê¸ˆ 5ë°° ì´ìƒ ê¸‰ì¦ (í°ì† ì§„ì…)

ì‚¬ìš©ë²•:
  python -m data.volume_scanner              # ì „ì²´ ìœ ë‹ˆë²„ìŠ¤ ìŠ¤ìº”
  python -m data.volume_scanner --top 20     # ìƒìœ„ 20ê°œë§Œ ì¶œë ¥
  python -m data.volume_scanner --telegram   # í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡
"""

import sys
import io
import json
import logging
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd

from data.indicator_calc import IndicatorCalc

logger = logging.getLogger(__name__)

BASE_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = BASE_DIR / "data_store"
DAILY_DIR = DATA_DIR / "daily"
RESULT_DIR = DATA_DIR / "scan_results"


# â”€â”€â”€ íŒ¨í„´ ê°ì§€ ì—”ì§„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def detect_patterns(df: pd.DataFrame, code: str, name: str) -> dict:
    """ì¼ë´‰ ë°ì´í„°ì—ì„œ 5ê°€ì§€ ì´ìƒê±°ë˜ íŒ¨í„´ì„ ê°ì§€í•œë‹¤.

    Args:
        df: ì¼ë´‰ DataFrame (ì»¬ëŸ¼: ì‹œê°€/ê³ ê°€/ì €ê°€/ì¢…ê°€/ê±°ë˜ëŸ‰ ë˜ëŠ” open/high/low/close/volume)
        code: ì¢…ëª©ì½”ë“œ
        name: ì¢…ëª©ëª…

    Returns:
        íŒ¨í„´ ê°ì§€ ê²°ê³¼ dict (patterns, spike_score ë“±)
    """
    # ì»¬ëŸ¼ í‘œì¤€í™”
    col_map = {
        "ì‹œê°€": "open", "ê³ ê°€": "high", "ì €ê°€": "low",
        "ì¢…ê°€": "close", "ê±°ë˜ëŸ‰": "volume", "ê±°ë˜ëŒ€ê¸ˆ": "trade_value",
    }
    df = df.rename(columns=col_map)

    required = ["open", "high", "low", "close", "volume"]
    for c in required:
        if c not in df.columns:
            return {"code": code, "name": name, "patterns": [], "spike_score": 0}

    if len(df) < 25:
        return {"code": code, "name": name, "patterns": [], "spike_score": 0}

    close = df["close"].astype(float)
    volume = df["volume"].astype(float)
    high = df["high"].astype(float)
    low = df["low"].astype(float)

    # ê±°ë˜ëŒ€ê¸ˆ (ì—†ìœ¼ë©´ ì¢…ê°€*ê±°ë˜ëŸ‰ìœ¼ë¡œ ê·¼ì‚¬)
    if "trade_value" in df.columns:
        trade_val = df["trade_value"].astype(float)
    else:
        trade_val = close * volume

    # 20ì¼ í‰ê·  ê±°ë˜ëŸ‰/ê±°ë˜ëŒ€ê¸ˆ
    vol_avg_20 = volume.rolling(20).mean()
    val_avg_20 = trade_val.rolling(20).mean()

    latest_vol = volume.iloc[-1]
    latest_val = trade_val.iloc[-1]
    latest_close = close.iloc[-1]
    prev_close = close.iloc[-2] if len(close) > 1 else latest_close
    price_change = abs(latest_close / prev_close - 1) * 100 if prev_close > 0 else 0

    avg_vol = vol_avg_20.iloc[-1] if not pd.isna(vol_avg_20.iloc[-1]) else 1
    avg_val = val_avg_20.iloc[-1] if not pd.isna(val_avg_20.iloc[-1]) else 1

    vol_ratio = latest_vol / max(avg_vol, 1)
    val_ratio = latest_val / max(avg_val, 1)

    patterns = []
    score = 0

    # â”€â”€â”€ íŒ¨í„´ 1: VOLUME_SPIKE (ê±°ë˜ëŸ‰ 2.5ë°°+) â”€â”€â”€
    if vol_ratio >= 2.5:
        pts = min(30, int((vol_ratio - 2.5) * 10) + 15)
        patterns.append({
            "type": "VOLUME_SPIKE",
            "description": f"ê±°ë˜ëŸ‰ {vol_ratio:.1f}ë°° ê¸‰ì¦",
            "score": pts,
        })
        score += pts

    # â”€â”€â”€ íŒ¨í„´ 2: QUIET_ACCUMULATION (3ë°°+ ê±°ë˜ëŸ‰ but ê°€ê²© 3% ë¯¸ë§Œ) â”€â”€â”€
    if vol_ratio >= 3.0 and price_change <= 3.0:
        pts = min(40, int((vol_ratio - 3.0) * 8) + 25)
        patterns.append({
            "type": "QUIET_ACCUMULATION",
            "description": f"ì¡°ìš©í•œ ë§¤ì§‘ â€” ê±°ë˜ëŸ‰ {vol_ratio:.1f}ë°°, ê°€ê²©ë³€ë™ {price_change:.1f}%",
            "score": pts,
        })
        score += pts

    # â”€â”€â”€ íŒ¨í„´ 3: OBV_BREAKOUT (OBV ì‹ ê³ ê°€, ì£¼ê°€ëŠ” ì•„ë‹˜) â”€â”€â”€
    obv_series = IndicatorCalc.obv(close, volume)
    obv_20_high = obv_series.tail(20).max()
    price_20_high = close.tail(20).max()

    obv_at_high = obv_series.iloc[-1] >= obv_20_high * 0.98
    price_not_high = close.iloc[-1] < price_20_high * 0.97

    if obv_at_high and price_not_high:
        pts = 20
        patterns.append({
            "type": "OBV_BREAKOUT",
            "description": f"OBV ì‹ ê³ ê°€ (ì£¼ê°€ ë¯¸ëŒíŒŒ) â€” ìê¸ˆ ì„ í–‰ ìœ ì…",
            "score": pts,
        })
        score += pts

    # â”€â”€â”€ íŒ¨í„´ 4: MULTI_DAY_ACCUM (3ì¼ ì—°ì† ê±°ë˜ëŸ‰ ì¦ê°€ + ì£¼ê°€ ìƒìŠ¹) â”€â”€â”€
    if len(volume) >= 4:
        vol_3d = volume.iloc[-3:]
        close_3d = close.iloc[-3:]
        vol_increasing = all(vol_3d.diff().dropna() > 0)
        price_rising = close_3d.iloc[-1] > close_3d.iloc[0]

        if vol_increasing and price_rising:
            pts = 20
            patterns.append({
                "type": "MULTI_DAY_ACCUM",
                "description": f"3ì¼ ì—°ì† ê±°ë˜ëŸ‰ ì¦ê°€ + ì£¼ê°€ ìƒìŠ¹",
                "score": pts,
            })
            score += pts

    # â”€â”€â”€ íŒ¨í„´ 5: BIG_MONEY_INFLOW (ê±°ë˜ëŒ€ê¸ˆ 5ë°°+) â”€â”€â”€
    if val_ratio >= 5.0:
        pts = min(35, int((val_ratio - 5.0) * 5) + 20)
        patterns.append({
            "type": "BIG_MONEY_INFLOW",
            "description": f"ê±°ë˜ëŒ€ê¸ˆ {val_ratio:.1f}ë°° ê¸‰ì¦ â€” í°ì† ì§„ì…",
            "score": pts,
        })
        score += pts

    # ìµœì¢… ì ìˆ˜ (100 cap)
    spike_score = min(100, score)

    return {
        "code": code,
        "name": name,
        "patterns": patterns,
        "spike_score": spike_score,
        "vol_ratio": round(vol_ratio, 2),
        "val_ratio": round(val_ratio, 2),
        "price_change": round(price_change, 2),
        "close": int(latest_close),
        "volume": int(latest_vol),
        "obv_trend": IndicatorCalc.obv_trend(close, volume),
        "detected_at": datetime.now().strftime("%Y-%m-%d %H:%M"),
    }


# â”€â”€â”€ ìŠ¤ìºë„ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def scan_universe(top_n: int = 30) -> list:
    """ìœ ë‹ˆë²„ìŠ¤ ì „ì²´ë¥¼ ìŠ¤ìº”í•˜ì—¬ ì´ìƒê±°ë˜ ì¢…ëª© ì¶”ì¶œ

    Returns:
        spike_score ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    from data.universe_builder import load_universe

    universe = load_universe()
    if not universe:
        logger.error("ìœ ë‹ˆë²„ìŠ¤ ì—†ìŒ â€” python -m data.universe_builder --build-only ì‹¤í–‰ í•„ìš”")
        return []

    print(f"\nğŸ” ì´ìƒê±°ë˜ ê°ì§€ê¸° â€” {len(universe)}ì¢…ëª© ìŠ¤ìº”")
    print("=" * 60)

    results = []
    scanned = 0
    skipped = 0

    for code, info in universe.items():
        name = info.get("name", code) if isinstance(info, dict) else info[0]
        daily_file = DAILY_DIR / f"{code}.csv"

        if not daily_file.exists():
            skipped += 1
            continue

        try:
            df = pd.read_csv(daily_file, index_col=0, parse_dates=True)
            if len(df) < 25:
                skipped += 1
                continue

            result = detect_patterns(df, code, name)
            if result["patterns"]:
                results.append(result)

            scanned += 1

        except Exception as e:
            logger.warning(f"  ìŠ¤ìº” ì‹¤íŒ¨ {code} {name}: {e}")
            skipped += 1

    # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ
    results.sort(key=lambda x: -x["spike_score"])
    results = results[:top_n]

    print(f"  ìŠ¤ìº”: {scanned}ì¢…ëª© | ê±´ë„ˆëœ€: {skipped}ì¢…ëª©")
    print(f"  ì´ìƒê±°ë˜ ê°ì§€: {len(results)}ì¢…ëª©")

    return results


def save_results(results: list) -> Path:
    """ìŠ¤ìº” ê²°ê³¼ ì €ì¥"""
    RESULT_DIR.mkdir(parents=True, exist_ok=True)

    today = datetime.now().strftime("%Y%m%d")

    # ì „ì²´ ê²°ê³¼
    full_path = RESULT_DIR / f"volume_spikes_{today}.json"
    with open(full_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    # extra_universe.json â€” QUIET_ACCUMULATION ì¢…ëª©ë§Œ (íŒŒì´í”„ë¼ì¸ ì—°ë™ìš©)
    quiet_stocks = [
        r for r in results
        if any(p["type"] == "QUIET_ACCUMULATION" for p in r["patterns"])
    ]
    extra_path = DATA_DIR / "extra_universe.json"
    extra = {
        r["code"]: {
            "name": r["name"],
            "source": "VOL_SPIKE",
            "spike_score": r["spike_score"],
            "patterns": [p["type"] for p in r["patterns"]],
        }
        for r in quiet_stocks
    }
    with open(extra_path, "w", encoding="utf-8") as f:
        json.dump(extra, f, ensure_ascii=False, indent=2)

    print(f"\n  ğŸ’¾ ì „ì²´ ê²°ê³¼: {full_path}")
    print(f"  ğŸ’¾ ì¡°ìš©í•œ ë§¤ì§‘: {extra_path} ({len(extra)}ì¢…ëª©)")

    return full_path


# â”€â”€â”€ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def format_results(results: list) -> str:
    """ê²°ê³¼ë¥¼ í…”ë ˆê·¸ë¨/ì½˜ì†”ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
    if not results:
        return "ì´ìƒê±°ë˜ ê°ì§€ ì—†ìŒ"

    lines = []
    lines.append(f"ğŸ” ì´ìƒê±°ë˜ ê°ì§€ ë¦¬í¬íŠ¸")
    lines.append(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    lines.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

    for i, r in enumerate(results[:15], 1):
        # íŒ¨í„´ ì•„ì´ì½˜
        pattern_icons = []
        for p in r["patterns"]:
            icons = {
                "VOLUME_SPIKE": "ğŸ“Š",
                "QUIET_ACCUMULATION": "ğŸ¤«",
                "OBV_BREAKOUT": "ğŸ’°",
                "MULTI_DAY_ACCUM": "ğŸ“ˆ",
                "BIG_MONEY_INFLOW": "ğŸ‹",
            }
            pattern_icons.append(icons.get(p["type"], "âš¡"))

        icon_str = "".join(pattern_icons)
        lines.append(f"\n{i}. {r['name']}({r['code']}) {icon_str}")
        lines.append(f"   ì ìˆ˜: {r['spike_score']}ì  | ì¢…ê°€: {r['close']:,}ì›")
        lines.append(f"   ê±°ë˜ëŸ‰: {r['vol_ratio']}ë°° | ê°€ê²©ë³€ë™: {r['price_change']}%")

        for p in r["patterns"]:
            lines.append(f"   â†’ {p['description']}")

    lines.append(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append(f"ğŸ¤« = ì¡°ìš©í•œë§¤ì§‘ | ğŸ‹ = í°ì† | ğŸ’° = OBVì„ í–‰")

    return "\n".join(lines)


def print_results(results: list):
    """ì½˜ì†” ì¶œë ¥"""
    print(format_results(results))


# â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
    logging.basicConfig(level=logging.WARNING)

    import argparse
    parser = argparse.ArgumentParser(description="ì´ìƒê±°ë˜ ê°ì§€ê¸°")
    parser.add_argument("--top", type=int, default=30, help="ìƒìœ„ Nê°œ (ê¸°ë³¸ 30)")
    parser.add_argument("--telegram", action="store_true", help="í…”ë ˆê·¸ë¨ ì•Œë¦¼")
    args = parser.parse_args()

    results = scan_universe(top_n=args.top)
    save_results(results)
    print_results(results)

    if args.telegram and results:
        try:
            from bot.telegram_bot import send_message
            msg = format_results(results)
            send_message(msg)
            print("\nğŸ“¨ í…”ë ˆê·¸ë¨ ì „ì†¡ ì™„ë£Œ")
        except Exception as e:
            print(f"\nâš ï¸ í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")
