"""
ë‰´ìŠ¤ AI ìŠ¤ìºë„ˆ (News AI Scanner)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ë‹¤ì¤‘ ì†ŒìŠ¤ ë‰´ìŠ¤ ìˆ˜ì§‘ â†’ Claude AI í†µí•© ë¶„ì„
â†’ ì¢…ëª©ë³„ ë‰´ìŠ¤ ì ìˆ˜ + ë§¤ìˆ˜/ê²½ê³  ì‹œê·¸ë„

ì†ŒìŠ¤:
  1. ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ (ì¢…ëª©ëª… + ì—…ì¢… í‚¤ì›Œë“œ)
  2. ë„¤ì´ë²„ ê¸ˆìœµ ì¢…ëª©ë³„ ë‰´ìŠ¤ (ê¸°ì¡´ news_collector ì¬ì‚¬ìš©)
  3. DART ê³µì‹œ (ê¸°ì¡´ event_detector ì¬ì‚¬ìš©)
  4. ì„¹í„°/í…Œë§ˆ ë‰´ìŠ¤ (ë°˜ë„ì²´, 2ì°¨ì „ì§€, ë°”ì´ì˜¤ ë“±)

AI ë¶„ì„:
  - Anthropic Claude API (ANTHROPIC_API_KEY)
  - ì¢…ëª©ë³„ ë‰´ìŠ¤ ê°ì„± + ì´‰ë§¤ ì´ë²¤íŠ¸ + ë¦¬ìŠ¤í¬ ë¶„ì„
"""
import os
import re
import json
import logging
import requests
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timedelta
from pathlib import Path

logger = logging.getLogger(__name__)

DATA_STORE = Path(__file__).parent.parent / "data_store" / "news_ai"

# â”€â”€ ì„¹í„° í‚¤ì›Œë“œ (ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ìš©) â”€â”€
SECTOR_KEYWORDS = {
    "ë°˜ë„ì²´": ["ë°˜ë„ì²´", "HBM", "íŒŒìš´ë“œë¦¬", "DRAM", "ë‚¸ë“œ", "AIì¹©"],
    "2ì°¨ì „ì§€": ["2ì°¨ì „ì§€", "ë°°í„°ë¦¬", "ë¦¬íŠ¬", "ì–‘ê·¹ì¬", "ìŒê·¹ì¬", "ì „ê³ ì²´"],
    "ë°”ì´ì˜¤": ["ë°”ì´ì˜¤", "ì„ìƒì‹œí—˜", "ì‹ ì•½", "FDA", "ë°”ì´ì˜¤ì‹œë°€ëŸ¬"],
    "ìë™ì°¨": ["ì „ê¸°ì°¨", "ììœ¨ì£¼í–‰", "í˜„ëŒ€ì°¨", "í…ŒìŠ¬ë¼", "ëª¨ë¹Œë¦¬í‹°"],
    "ë°©ì‚°": ["ë°©ì‚°", "ë¬´ê¸°ìˆ˜ì¶œ", "Kë°©ì‚°", "í•œí™”ì—ì–´ë¡œ", "LIGë„¥ìŠ¤ì›"],
    "AI": ["ì¸ê³µì§€ëŠ¥", "AI", "ì—”ë¹„ë””ì•„", "ì±—GPT", "LLM", "GPU"],
    "ì›ì „": ["ì›ì „", "SMR", "ì†Œí˜•ëª¨ë“ˆì›ì „", "ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°", "ì›ìë ¥"],
    "ì¡°ì„ ": ["ì¡°ì„ ", "LNGì„ ", "HDí•œêµ­ì¡°ì„ ", "ì‚¼ì„±ì¤‘ê³µì—…"],
}

# â”€â”€ ì¢…ëª©â†”ì„¹í„° ë§¤í•‘ â”€â”€
STOCK_SECTOR_MAP = {
    "005930": "ë°˜ë„ì²´",   # ì‚¼ì„±ì „ì
    "000660": "ë°˜ë„ì²´",   # SKí•˜ì´ë‹‰ìŠ¤
    "006400": "2ì°¨ì „ì§€",  # ì‚¼ì„±SDI
    "051910": "2ì°¨ì „ì§€",  # LGí™”í•™
    "003670": "2ì°¨ì „ì§€",  # í¬ìŠ¤ì½”í“¨ì²˜ì— 
    "005380": "ìë™ì°¨",   # í˜„ëŒ€ì°¨
    "000270": "ìë™ì°¨",   # ê¸°ì•„
    "207940": "ë°”ì´ì˜¤",   # ì‚¼ì„±ë°”ì´ì˜¤
    "068270": "ë°”ì´ì˜¤",   # ì…€íŠ¸ë¦¬ì˜¨
    "012450": "AI",       # í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤
    "042700": "AI",       # í•œë¯¸ë°˜ë„ì²´
    "034730": "AI",       # SK
    "009540": "ì¡°ì„ ",     # HDí•œêµ­ì¡°ì„ í•´ì–‘
}


@dataclass
class NewsItem:
    """ê°œë³„ ë‰´ìŠ¤ í•­ëª©"""
    title: str
    source: str           # naver_search, naver_finance, dart, sector
    date: str             # YYYY-MM-DD
    url: str = ""
    snippet: str = ""
    relevance: str = ""   # AIê°€ íŒë‹¨í•œ ê´€ë ¨ë„


@dataclass
class NewsAIResult:
    """AI ë¶„ì„ ê²°ê³¼"""
    code: str
    name: str
    news_score: float           # -100 ~ +100
    news_grade: str             # STRONG_POSITIVE, POSITIVE, NEUTRAL, NEGATIVE, STRONG_NEGATIVE
    catalyst_count: int         # ì´‰ë§¤ ì´ë²¤íŠ¸ ìˆ˜
    risk_count: int             # ë¦¬ìŠ¤í¬ ì´ë²¤íŠ¸ ìˆ˜
    catalysts: List[str]        # ì´‰ë§¤ ëª©ë¡
    risks: List[str]            # ë¦¬ìŠ¤í¬ ëª©ë¡
    ai_summary: str             # AI ìš”ì•½ (1~2ì¤„)
    ai_recommendation: str      # AI ì¶”ì²œ ì½”ë©˜íŠ¸
    sector_sentiment: str       # ì„¹í„° ì „ì²´ ë¶„ìœ„ê¸°
    news_count: int             # ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ìˆ˜
    top_headlines: List[str]    # ì£¼ìš” í—¤ë“œë¼ì¸ TOP 5


def fetch_naver_news_search(query: str, max_items: int = 10) -> List[NewsItem]:
    """Google News RSSë¡œ í•œêµ­ ë‰´ìŠ¤ ê²€ìƒ‰ (ë„¤ì´ë²„ ê²€ìƒ‰ì€ JS ë Œë”ë§ì´ë¼ ì‚¬ìš© ë¶ˆê°€)"""
    items = []
    try:
        import urllib.parse
        encoded = urllib.parse.quote(query)
        url = f"https://news.google.com/rss/search?q={encoded}&hl=ko&gl=KR&ceid=KR:ko"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                          "AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36"
        }
        resp = requests.get(url, headers=headers, timeout=10)
        resp.encoding = "utf-8"
        xml = resp.text

        # RSS XMLì—ì„œ ì œëª© ì¶”ì¶œ
        titles = re.findall(r'<title><!\[CDATA\[(.*?)\]\]></title>', xml)
        if not titles:
            titles = re.findall(r'<title>(.*?)</title>', xml)

        # ì²« ë²ˆì§¸ëŠ” í”¼ë“œ ì œëª©ì´ë¯€ë¡œ ìŠ¤í‚µ
        for title in titles[1:max_items + 1]:
            title = re.sub(r'<[^>]+>', '', title).strip()
            # " - ë§¤ì²´ëª…" ë¶„ë¦¬
            parts = title.rsplit(" - ", 1)
            headline = parts[0].strip()
            source_name = parts[1].strip() if len(parts) > 1 else ""

            if headline and len(headline) > 5:
                items.append(NewsItem(
                    title=headline,
                    source=f"google_news({source_name})" if source_name else "google_news",
                    date=datetime.now().strftime("%Y-%m-%d"),
                ))

    except Exception as e:
        logger.warning(f"Google News RSS ì‹¤íŒ¨ ({query}): {e}")

    return items


def fetch_stock_news(code: str, name: str) -> List[NewsItem]:
    """ë„¤ì´ë²„ ê¸ˆìœµ ì¢…ëª©ë³„ ë‰´ìŠ¤ (NewsCollector í´ë˜ìŠ¤ ì‚¬ìš©)"""
    items = []
    try:
        from data.news_collector import NewsCollector
        nc = NewsCollector()
        headlines = nc.fetch_naver_news(code, count=10)
        for h in headlines:
            title = h.get("title", "") if isinstance(h, dict) else str(h)
            if title:
                items.append(NewsItem(
                    title=title,
                    source="naver_finance",
                    date=datetime.now().strftime("%Y-%m-%d"),
                ))
    except Exception as e:
        logger.warning(f"ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ ({code}): {e}")
    return items


def fetch_dart_disclosures(code: str, name: str) -> List[NewsItem]:
    """DART ê³µì‹œ â€” ì „ì²´ ê³µì‹œì—ì„œ í•´ë‹¹ ì¢…ëª© í•„í„°ë§"""
    items = []
    try:
        from data.event_detector import fetch_dart_disclosures as dart_fetch
        disclosures = dart_fetch(days_back=7)
        for d in disclosures:
            if not isinstance(d, dict):
                continue
            # ì¢…ëª©ëª… ë§¤ì¹­
            corp = d.get("corp_name", "")
            if name and name[:2] in corp:  # ì• 2ê¸€ì ë§¤ì¹­
                title = d.get("report_nm", "")
                event_type = d.get("event_type", "")
                items.append(NewsItem(
                    title=f"[ê³µì‹œ] {title}" + (f" ({event_type})" if event_type else ""),
                    source="dart",
                    date=d.get("rcept_dt", ""),
                ))
        items = items[:5]
    except Exception as e:
        logger.debug(f"DART ê³µì‹œ ìˆ˜ì§‘ ì‹¤íŒ¨ ({code}): {e}")
    return items


def fetch_sector_news(code: str) -> List[NewsItem]:
    """ì„¹í„°/í…Œë§ˆ ë‰´ìŠ¤ ê²€ìƒ‰"""
    sector = STOCK_SECTOR_MAP.get(code, "")
    if not sector:
        return []

    keywords = SECTOR_KEYWORDS.get(sector, [])
    if not keywords:
        return []

    # ì„¹í„°ì˜ ì²« ë²ˆì§¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
    items = fetch_naver_news_search(keywords[0], max_items=5)
    for item in items:
        item.source = f"sector_{sector}"
    return items


def collect_all_news(code: str, name: str) -> List[NewsItem]:
    """ë‹¤ì¤‘ ì†ŒìŠ¤ ë‰´ìŠ¤ í†µí•© ìˆ˜ì§‘"""
    all_items = []

    # 1. ì¢…ëª©ëª…ìœ¼ë¡œ ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰
    all_items.extend(fetch_naver_news_search(name, max_items=8))

    # 2. ë„¤ì´ë²„ ê¸ˆìœµ ì¢…ëª© ë‰´ìŠ¤
    all_items.extend(fetch_stock_news(code, name))

    # 3. DART ê³µì‹œ
    all_items.extend(fetch_dart_disclosures(code, name))

    # 4. ì„¹í„° ë‰´ìŠ¤
    all_items.extend(fetch_sector_news(code))

    # ì¤‘ë³µ ì œê±° (ì œëª© ê¸°ì¤€)
    seen = set()
    unique = []
    for item in all_items:
        key = item.title[:30]  # ì• 30ìë¡œ ì¤‘ë³µ ì²´í¬
        if key not in seen:
            seen.add(key)
            unique.append(item)

    return unique


def analyze_with_claude(code: str, name: str,
                        news_items: List[NewsItem],
                        supply_context: str = "") -> Optional[NewsAIResult]:
    """Claude AIë¡œ ë‰´ìŠ¤ í†µí•© ë¶„ì„

    Args:
        code: ì¢…ëª©ì½”ë“œ
        name: ì¢…ëª©ëª…
        news_items: ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ëª©ë¡
        supply_context: ìˆ˜ê¸‰ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒ)

    Returns:
        NewsAIResult or None
    """
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        logger.error("ANTHROPIC_API_KEY ì—†ìŒ")
        return None

    if not news_items:
        return NewsAIResult(
            code=code, name=name, news_score=0, news_grade="NEUTRAL",
            catalyst_count=0, risk_count=0, catalysts=[], risks=[],
            ai_summary="ë‰´ìŠ¤ ì—†ìŒ", ai_recommendation="ë°ì´í„° ë¶€ì¡±",
            sector_sentiment="UNKNOWN", news_count=0, top_headlines=[],
        )

    # ë‰´ìŠ¤ í…ìŠ¤íŠ¸ êµ¬ì„±
    news_text = ""
    for i, item in enumerate(news_items[:20], 1):
        news_text += f"{i}. [{item.source}] {item.title}"
        if item.snippet:
            news_text += f"\n   {item.snippet[:100]}"
        news_text += "\n"

    prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë¬¸ ë‰´ìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ì¢…ëª©: {name} ({code})
{f'ìˆ˜ê¸‰ ì»¨í…ìŠ¤íŠ¸: {supply_context}' if supply_context else ''}

ì•„ë˜ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ê³  JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

{news_text}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ì„¤ëª… ì—†ì´ JSONë§Œ):
{{
  "news_score": <-100~+100 ì •ìˆ˜. ì–‘ìˆ˜=í˜¸ì¬, ìŒìˆ˜=ì•…ì¬>,
  "news_grade": "<STRONG_POSITIVE|POSITIVE|NEUTRAL|NEGATIVE|STRONG_NEGATIVE>",
  "catalysts": ["ì´‰ë§¤1", "ì´‰ë§¤2"],
  "risks": ["ë¦¬ìŠ¤í¬1", "ë¦¬ìŠ¤í¬2"],
  "ai_summary": "1~2ì¤„ í•µì‹¬ ìš”ì•½",
  "ai_recommendation": "ë§¤ìˆ˜/ê´€ë§/ê²½ê³  + ì´ìœ  1ì¤„",
  "sector_sentiment": "<BULLISH|NEUTRAL|BEARISH>",
  "top_headlines": ["ê°€ì¥ ì¤‘ìš”í•œ í—¤ë“œë¼ì¸ ìµœëŒ€ 3ê°œ"]
}}

ë¶„ì„ ê¸°ì¤€:
- ì‹¤ì /ë§¤ì¶œ ê´€ë ¨: ì‹¤ì  ì„œí”„ë¼ì´ì¦ˆ=+30~50, ì‹¤ì  ë¯¸ìŠ¤=-30~50
- ìˆ˜ì£¼/ê³„ì•½: ëŒ€í˜• ìˆ˜ì£¼=+20~40
- ê·œì œ/ë²•ì  ì´ìŠˆ: -20~-50
- í…Œë§ˆ/ì„¹í„° í˜¸ì¬: +10~30
- ë‹¨ìˆœ ì–¸ê¸‰/ì¤‘ë¦½: 0
- ë‰´ìŠ¤ ì—†ìœ¼ë©´ score=0, grade=NEUTRAL"""

    try:
        resp = requests.post(
            "https://api.anthropic.com/v1/messages",
            headers={
                "x-api-key": api_key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json",
            },
            json={
                "model": "claude-haiku-4-5-20251001",
                "max_tokens": 1024,
                "messages": [{"role": "user", "content": prompt}],
            },
            timeout=30,
        )

        if resp.status_code != 200:
            logger.error(f"Claude API ì˜¤ë¥˜ {resp.status_code}: {resp.text[:200]}")
            return None

        data = resp.json()
        text = data["content"][0]["text"].strip()

        # JSON íŒŒì‹± (```json ë¸”ë¡ ì²˜ë¦¬)
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            text = text.split("```")[1].split("```")[0].strip()

        result = json.loads(text)

        return NewsAIResult(
            code=code,
            name=name,
            news_score=int(result.get("news_score", 0)),
            news_grade=result.get("news_grade", "NEUTRAL"),
            catalyst_count=len(result.get("catalysts", [])),
            risk_count=len(result.get("risks", [])),
            catalysts=result.get("catalysts", []),
            risks=result.get("risks", []),
            ai_summary=result.get("ai_summary", ""),
            ai_recommendation=result.get("ai_recommendation", ""),
            sector_sentiment=result.get("sector_sentiment", "NEUTRAL"),
            news_count=len(news_items),
            top_headlines=result.get("top_headlines", []),
        )

    except json.JSONDecodeError as e:
        logger.error(f"Claude ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        logger.error(f"Claude API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None


def scan_news_ai(candidates: list, save: bool = True) -> List[NewsAIResult]:
    """ì‚¬ì „ê°ì§€ í›„ë³´ì— ëŒ€í•œ ë‰´ìŠ¤ AI ë¶„ì„

    Args:
        candidates: PreMoveCandidate ë˜ëŠ” {code, name} dict ë¦¬ìŠ¤íŠ¸
        save: ê²°ê³¼ ì €ì¥ ì—¬ë¶€

    Returns:
        ì¢…ëª©ë³„ NewsAIResult ë¦¬ìŠ¤íŠ¸
    """
    results = []

    for c in candidates:
        code = c.code if hasattr(c, "code") else c.get("code", "")
        name = c.name if hasattr(c, "name") else c.get("name", "")

        if not code or not name:
            continue

        print(f"  ë‰´ìŠ¤ ìˆ˜ì§‘: {name}({code})...")
        news_items = collect_all_news(code, name)
        print(f"    ìˆ˜ì§‘ ì™„ë£Œ: {len(news_items)}ê±´")

        # ìˆ˜ê¸‰ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        supply_ctx = ""
        if hasattr(c, "supply_grade"):
            supply_ctx = (
                f"ìˆ˜ê¸‰ë“±ê¸‰:{c.supply_grade}, ëª¨ë©˜í…€:{c.momentum_signal}, "
                f"ì—ë„ˆì§€:{c.energy_grade}, ê¸°ê´€ì—°ì†ë§¤ìˆ˜:{c.inst_streak}ì¼"
            )

        print(f"    AI ë¶„ì„ ì¤‘...")
        result = analyze_with_claude(code, name, news_items, supply_ctx)

        if result:
            results.append(result)
            grade_emoji = {
                "STRONG_POSITIVE": "ğŸ”¥",
                "POSITIVE": "âœ…",
                "NEUTRAL": "âšª",
                "NEGATIVE": "âš ï¸",
                "STRONG_NEGATIVE": "ğŸš¨",
            }
            emoji = grade_emoji.get(result.news_grade, "âšª")
            print(f"    â†’ {emoji} {result.news_grade} (ì ìˆ˜: {result.news_score:+d})")
        else:
            print(f"    â†’ ë¶„ì„ ì‹¤íŒ¨")

    # ì €ì¥
    if save and results:
        DATA_STORE.mkdir(parents=True, exist_ok=True)
        today = datetime.now().strftime("%Y%m%d")
        path = DATA_STORE / f"news_ai_{today}.json"
        data = []
        for r in results:
            data.append({
                "code": r.code, "name": r.name,
                "news_score": r.news_score, "news_grade": r.news_grade,
                "catalyst_count": r.catalyst_count, "risk_count": r.risk_count,
                "catalysts": r.catalysts, "risks": r.risks,
                "ai_summary": r.ai_summary, "ai_recommendation": r.ai_recommendation,
                "sector_sentiment": r.sector_sentiment,
                "news_count": r.news_count, "top_headlines": r.top_headlines,
            })
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"\nì €ì¥: {path}")

    return results


def format_news_ai_report(results: List[NewsAIResult]) -> str:
    """í…”ë ˆê·¸ë¨ìš© ë‰´ìŠ¤ AI ë¦¬í¬íŠ¸"""
    if not results:
        return "ğŸ“° ë‰´ìŠ¤ AI: ë¶„ì„ ê²°ê³¼ ì—†ìŒ"

    grade_emoji = {
        "STRONG_POSITIVE": "ğŸ”¥",
        "POSITIVE": "âœ…",
        "NEUTRAL": "âšª",
        "NEGATIVE": "âš ï¸",
        "STRONG_NEGATIVE": "ğŸš¨",
    }

    lines = ["ğŸ“° ë‰´ìŠ¤ AI ë¶„ì„", "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"]

    for r in sorted(results, key=lambda x: x.news_score, reverse=True):
        emoji = grade_emoji.get(r.news_grade, "âšª")
        lines.append(f"\n{emoji} {r.name}({r.code})")
        lines.append(f"  ì ìˆ˜: {r.news_score:+d} | {r.news_grade}")
        lines.append(f"  ë‰´ìŠ¤: {r.news_count}ê±´ | ì„¹í„°: {r.sector_sentiment}")

        if r.catalysts:
            lines.append(f"  ì´‰ë§¤: {' / '.join(r.catalysts[:3])}")
        if r.risks:
            lines.append(f"  ë¦¬ìŠ¤í¬: {' / '.join(r.risks[:2])}")

        lines.append(f"  AI: {r.ai_summary}")
        lines.append(f"  ì¶”ì²œ: {r.ai_recommendation}")

    lines.append(f"\n{datetime.now().strftime('%Y-%m-%d %H:%M')}")
    return "\n".join(lines)


# â”€â”€ CLI â”€â”€
if __name__ == "__main__":
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from dotenv import load_dotenv
    load_dotenv(str(Path(__file__).parent.parent.parent / ".env"))

    print("=" * 60)
    print("  ğŸ“° ë‰´ìŠ¤ AI ìŠ¤ìºë„ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # ì‚¬ì „ê°ì§€ í›„ë³´ ë¡œë“œ
    try:
        from data.premove_scanner import scan_premove
        print("\nì‚¬ì „ê°ì§€ ìŠ¤ìº” ì‹¤í–‰...")
        candidates = scan_premove(top_n=5)
    except Exception as e:
        print(f"ì‚¬ì „ê°ì§€ ì‹¤íŒ¨: {e}")
        # í´ë°±: ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ì¢…ëª©
        candidates = [
            {"code": "005930", "name": "ì‚¼ì„±ì „ì"},
            {"code": "000660", "name": "SKí•˜ì´ë‹‰ìŠ¤"},
        ]

    if not candidates:
        print("í›„ë³´ ì—†ìŒ â€” í…ŒìŠ¤íŠ¸ ì¢…ëª© ì‚¬ìš©")
        candidates = [
            {"code": "005930", "name": "ì‚¼ì„±ì „ì"},
            {"code": "000660", "name": "SKí•˜ì´ë‹‰ìŠ¤"},
        ]

    print(f"\në‰´ìŠ¤ AI ë¶„ì„ ì‹œì‘ ({len(candidates)}ì¢…ëª©)...")
    print("â”€" * 60)

    results = scan_news_ai(candidates)

    print("\n" + "=" * 60)
    print(format_news_ai_report(results))
