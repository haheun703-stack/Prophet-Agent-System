# -*- coding: utf-8 -*-
"""
ì´ë²¤íŠ¸ ê°ì§€ê¸° â€” DART ê³µì‹œ + ë„¤ì´ë²„ ë‰´ìŠ¤ í…Œë§ˆ ìŠ¤ìº”
====================================================
DART ì „ìê³µì‹œì—ì„œ ìì‚¬ì£¼/ëŒ€ê·œëª¨ìˆ˜ì£¼/ì„ìƒ ë“±ì„ ìë™ ë¶„ë¥˜í•˜ê³ ,
ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ 10ëŒ€ í…Œë§ˆ í‚¤ì›Œë“œë¥¼ ìŠ¤ìº”í•˜ì—¬ ìˆ˜í˜œì£¼ë¥¼ ë§¤ì¹­í•œë‹¤.

íŒŒì´í”„ë¼ì¸:
  1. DART API â†’ ê³µì‹œ ë¶„ë¥˜ â†’ ì§ì ‘ ìˆ˜í˜œì£¼
  2. ë„¤ì´ë²„ ë‰´ìŠ¤ â†’ í…Œë§ˆ ê°ì§€ â†’ ê°„ì ‘ ìˆ˜í˜œì£¼ (BENEFICIARY_DB)
  3. ìˆ˜í˜œì£¼ ìŠ¤ì½”ì–´ ì§‘ê³„ â†’ ìŠ¤ìœ™ íŒŒì´í”„ë¼ì¸ ì „ë‹¬

ì‚¬ìš©ë²•:
  python -m data.event_detector                    # ì „ì²´ ìŠ¤ìº”
  python -m data.event_detector --dart-only        # DARTë§Œ
  python -m data.event_detector --news-only        # ë‰´ìŠ¤ë§Œ
  python -m data.event_detector --telegram         # í…”ë ˆê·¸ë¨ ì „ì†¡

í™˜ê²½ë³€ìˆ˜:
  DART_API_KEY â€” DART OpenAPI ì¸ì¦í‚¤ (opendart.fss.or.kr)
"""

import os
import sys
import io
import json
import logging
import time
import re
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Optional

import requests

logger = logging.getLogger(__name__)

BASE_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = BASE_DIR / "data_store"
MACRO_THEMES_PATH = DATA_DIR / "macro_themes.json"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ê³µì‹œ ë¶„ë¥˜ ê·œì¹™
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EVENT_RULES = [
    # (keywords, event_type, impact, direction)
    (["ìê¸°ì£¼ì‹ì·¨ë“", "ìì‚¬ì£¼ì·¨ë“", "ìì‚¬ì£¼ë§¤ì…", "ìê¸°ì£¼ì‹ ì·¨ë“"],
     "TREASURY_BUY", 85, "POSITIVE"),
    (["ìê¸°ì£¼ì‹ì†Œê°", "ìì‚¬ì£¼ì†Œê°"],
     "TREASURY_CANCEL", 90, "POSITIVE"),
    (["ìê¸°ì£¼ì‹ì²˜ë¶„", "ìì‚¬ì£¼ì²˜ë¶„"],
     "TREASURY_SELL", 60, "NEGATIVE"),
    (["ë‹¨ì¼íŒë§¤ê³µê¸‰ê³„ì•½", "ëŒ€ê·œëª¨ê³µê¸‰ê³„ì•½", "ìˆ˜ì£¼ê³µì‹œ", "ëŒ€ê·œëª¨ ìˆ˜ì£¼"],
     "BIG_CONTRACT", 80, "POSITIVE"),
    (["ì„ìƒ", "FDA", "ì‹ì•½ì²˜"],
     "CLINICAL_TRIAL", 80, "POSITIVE"),
    (["íŠ¹í—ˆì·¨ë“", "íŠ¹í—ˆë“±ë¡"],
     "PATENT", 60, "POSITIVE"),
    (["ìµœëŒ€ì£¼ì£¼ë³€ê²½"],
     "OWNER_CHANGE", 75, "NEUTRAL"),
    (["ìœ ìƒì¦ì"],
     "RIGHTS_ISSUE", 70, "NEGATIVE"),
    (["ë¬´ìƒì¦ì"],
     "FREE_ISSUE", 65, "POSITIVE"),
    (["í•©ë³‘", "í¡ìˆ˜í•©ë³‘"],
     "MERGER", 70, "NEUTRAL"),
    (["ë¶„í• ", "ë¬¼ì ë¶„í• ", "ì¸ì ë¶„í• "],
     "SPLIT", 65, "NEGATIVE"),
    (["ì˜ì—…ì •ì§€", "ìƒì¥íì§€", "ê°ì‚¬ì˜ê²¬ê±°ì ˆ"],
     "DELISTING_RISK", 95, "NEGATIVE"),
    (["ì ì •ì‹¤ì ", "ì˜ì—…ì´ìµ"],
     "EARNINGS", 70, "NEUTRAL"),
]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  10ëŒ€ í…Œë§ˆ í‚¤ì›Œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

THEME_KEYWORDS = {
    "ìƒë²•ê°œì •": {
        "keywords": ["ìƒë²• ê°œì •", "ìì‚¬ì£¼ ì†Œê°", "ìì‚¬ì£¼ ë§¤ì…", "ì£¼ì£¼í™˜ì›", "ë°°ë‹¹ í™•ëŒ€"],
        "impact": 85,
        "direction": "POSITIVE",
        "tag": "treasury_stock",
    },
    "ë°˜ë„ì²´ìŠˆí¼ì‚¬ì´í´": {
        "keywords": ["HBM", "AI ë°˜ë„ì²´", "HBM4", "ê³ ëŒ€ì—­í­", "ì—”ë¹„ë””ì•„ ì‹¤ì ", "íŒŒìš´ë“œë¦¬"],
        "impact": 80,
        "direction": "POSITIVE",
        "tag": "semiconductor",
    },
    "ì›ì „ë¥´ë„¤ìƒìŠ¤": {
        "keywords": ["ì›ì „ ìˆ˜ì¶œ", "SMR", "ì†Œí˜•ëª¨ë“ˆì›ì „", "ì›ì „ ì¬ê°€ë™", "ì²´ì½” ì›ì „"],
        "impact": 75,
        "direction": "POSITIVE",
        "tag": "nuclear",
    },
    "ë°©ì‚°ìˆ˜ì£¼": {
        "keywords": ["ë°©ì‚° ìˆ˜ì¶œ", "K-ë°©ì‚°", "K2 ì „ì°¨", "FA-50", "ì²œë¬´", "K9 ìì£¼í¬"],
        "impact": 75,
        "direction": "POSITIVE",
        "tag": "defense",
    },
    "AIíˆ¬ì": {
        "keywords": ["AI íˆ¬ì", "ë°ì´í„°ì„¼í„°", "AI ì¸í”„ë¼", "í´ë¼ìš°ë“œ íˆ¬ì", "GPU ìˆ˜ìš”", "AI ì„œë²„"],
        "impact": 80,
        "direction": "POSITIVE",
        "tag": "ai",
    },
    "ê¸ˆë¦¬ì¸í•˜": {
        "keywords": ["ê¸ˆë¦¬ ì¸í•˜", "ê¸°ì¤€ê¸ˆë¦¬ ì¸í•˜", "Fed ê¸ˆë¦¬", "í•œì€ ê¸ˆë¦¬", "í”¼ë²—"],
        "impact": 70,
        "direction": "POSITIVE",
        "tag": "rate_sensitive",
    },
    "ê¸ˆë¦¬ì¸ìƒê²½ê³ ": {
        "keywords": ["ê¸ˆë¦¬ ì¸ìƒ", "ê¸ˆë¦¬ ë™ê²° ì¥ê¸°í™”", "ì¸í”Œë ˆì´ì…˜ ìš°ë ¤", "ìŠ¤íƒœê·¸í”Œë ˆì´ì…˜"],
        "impact": 80,
        "direction": "NEGATIVE",
        "tag": "market_risk",
    },
    "ê´€ì„¸ë¦¬ìŠ¤í¬": {
        "keywords": ["ê´€ì„¸ ë¶€ê³¼", "ë¬´ì—­ì „ìŸ", "ë°˜ë„ì²´ ê´€ì„¸", "ìë™ì°¨ ê´€ì„¸"],
        "impact": 65,
        "direction": "NEGATIVE",
        "tag": "tariff_risk",
    },
    "MSCIì„ ì§„êµ­": {
        "keywords": ["MSCI ì„ ì§„êµ­", "MSCI í¸ì…", "ëª¨ê±´ìŠ¤íƒ ë¦¬ ì§€ìˆ˜"],
        "impact": 85,
        "direction": "POSITIVE",
        "tag": "msci",
    },
    "ë°”ì´ì˜¤ì„ìƒ": {
        "keywords": ["FDA ìŠ¹ì¸", "ì„ìƒ 3ìƒ", "ì‹ ì•½ í—ˆê°€", "ê¸´ê¸‰ì‚¬ìš©ìŠ¹ì¸", "ë¸”ë¡ë²„ìŠ¤í„°"],
        "impact": 80,
        "direction": "POSITIVE",
        "tag": "bio",
    },
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ìˆ˜í˜œì£¼ DB (í…Œë§ˆ â†’ ì¢…ëª©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BENEFICIARY_DB = {
    "treasury_stock": [
        ("085620", "ë¯¸ë˜ì—ì…‹ìƒëª…", 95, "ìì‚¬ì£¼ 26.3%"),
        ("088350", "í•œí™”ìƒëª…", 90, "ìì‚¬ì£¼ 18.5%"),
        ("005830", "DBì†í•´ë³´í—˜", 85, "ìì‚¬ì£¼ 14.5%"),
        ("032830", "ì‚¼ì„±ìƒëª…", 85, "ìì‚¬ì£¼ 10.8%"),
        ("000810", "ì‚¼ì„±í™”ì¬", 80, "ìì‚¬ì£¼ 9.5%"),
        ("001450", "í˜„ëŒ€í•´ìƒ", 78, "ìì‚¬ì£¼ 8.2%"),
        ("003690", "ì½”ë¦¬ì•ˆë¦¬", 75, "ìì‚¬ì£¼ 7.8%"),
        ("005930", "ì‚¼ì„±ì „ì", 65, "ìì‚¬ì£¼ 5.2%"),
    ],
    "semiconductor": [
        ("000660", "SKí•˜ì´ë‹‰ìŠ¤", 95, "HBM ì„¸ê³„ 1ìœ„"),
        ("005930", "ì‚¼ì„±ì „ì", 90, "ë©”ëª¨ë¦¬+íŒŒìš´ë“œë¦¬"),
        ("403870", "HPSP", 80, "ë°˜ë„ì²´ ì¥ë¹„"),
        ("058470", "ë¦¬ë…¸ê³µì—…", 78, "ë°˜ë„ì²´ í…ŒìŠ¤íŠ¸"),
        ("042700", "í•œë¯¸ë°˜ë„ì²´", 75, "íŒ¨í‚¤ì§• ì¥ë¹„"),
    ],
    "nuclear": [
        ("034020", "ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°", 90, "ì›ì „ í•µì‹¬ ê¸°ìì¬"),
        ("000720", "í˜„ëŒ€ê±´ì„¤", 80, "ì›ì „ ê±´ì„¤"),
    ],
    "defense": [
        ("012450", "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤", 90, "í•­ê³µì—”ì§„+ë°©ì‚°"),
        ("047810", "í•œêµ­í•­ê³µìš°ì£¼", 85, "FA-50 í•­ê³µê¸°"),
    ],
    "ai": [
        ("035420", "NAVER", 85, "AI+í´ë¼ìš°ë“œ"),
        ("035720", "ì¹´ì¹´ì˜¤", 75, "AI+í”Œë«í¼"),
        ("012510", "ë”ì¡´ë¹„ì¦ˆì˜¨", 70, "AI ERP"),
    ],
    "bio": [
        ("207940", "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", 85, "CMO ì„¸ê³„ 1ìœ„"),
        ("068270", "ì…€íŠ¸ë¦¬ì˜¨", 80, "ë°”ì´ì˜¤ì‹œë°€ëŸ¬"),
    ],
    "rate_sensitive": [
        ("005830", "DBì†í•´ë³´í—˜", 70, "ë³´í—˜"),
        ("088350", "í•œí™”ìƒëª…", 70, "ìƒëª…ë³´í—˜"),
    ],
    "msci": [
        ("005930", "ì‚¼ì„±ì „ì", 90, "MSCI ëŒ€í˜•ì£¼"),
        ("000660", "SKí•˜ì´ë‹‰ìŠ¤", 85, "MSCI í¸ì… ìˆ˜í˜œ"),
    ],
    "market_risk": [],   # ë¦¬ìŠ¤í¬ ê²½ê³  (ë§¤ìˆ˜ ìˆ˜í˜œì£¼ ì—†ìŒ)
    "tariff_risk": [],   # ë¦¬ìŠ¤í¬ ê²½ê³ 
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ë§¤í¬ë¡œ í…Œë§ˆ ë™ì  ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_macro_themes():
    """macro_themes.jsonì—ì„œ ACTIVE í…Œë§ˆë¥¼ THEME_KEYWORDS/BENEFICIARY_DBì— merge"""
    if not MACRO_THEMES_PATH.exists():
        return 0

    try:
        with open(MACRO_THEMES_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
    except (json.JSONDecodeError, IOError) as e:
        logger.warning(f"macro_themes.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        return 0

    merged = 0
    for theme in data.get("themes", []):
        if theme.get("status") != "ACTIVE":
            continue

        tag = theme.get("tag", "")
        name = theme.get("name", tag)
        if not tag:
            continue

        # THEME_KEYWORDSì— ì¶”ê°€ (ì´ë¯¸ ìˆìœ¼ë©´ ìŠ¤í‚µ)
        if name not in THEME_KEYWORDS:
            THEME_KEYWORDS[name] = {
                "keywords": theme.get("keywords", []),
                "impact": theme.get("impact", 70),
                "direction": theme.get("direction", "NEUTRAL"),
                "tag": tag,
            }

        # BENEFICIARY_DBì— ì¶”ê°€
        if tag not in BENEFICIARY_DB:
            BENEFICIARY_DB[tag] = []

        existing_tickers = {t[0] for t in BENEFICIARY_DB[tag]}
        for b in theme.get("beneficiaries", []):
            if b["ticker"] not in existing_tickers:
                BENEFICIARY_DB[tag].append(
                    (b["ticker"], b["name"], b["relevance"], b["metric"])
                )

        merged += 1

    if merged:
        logger.info(f"ë§¤í¬ë¡œ í…Œë§ˆ {merged}ê°œ merge ì™„ë£Œ")
    return merged


def get_macro_themes() -> list:
    """macro_themes.json ì „ì²´ ë°˜í™˜ (í…”ë ˆê·¸ë¨ ëª…ë ¹ìš©)"""
    if not MACRO_THEMES_PATH.exists():
        return []
    try:
        with open(MACRO_THEMES_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data.get("themes", [])
    except (json.JSONDecodeError, IOError):
        return []


def update_macro_theme_status(theme_id: str, new_status: str) -> bool:
    """í…Œë§ˆ ìƒíƒœ ë³€ê²½ (ACTIVE/WATCH/ARCHIVE)"""
    if new_status not in ("ACTIVE", "WATCH", "ARCHIVE"):
        return False
    if not MACRO_THEMES_PATH.exists():
        return False
    try:
        with open(MACRO_THEMES_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
        for theme in data.get("themes", []):
            if theme.get("id") == theme_id:
                theme["status"] = new_status
                data["_meta"]["updated_at"] = datetime.now().strftime("%Y-%m-%d")
                with open(MACRO_THEMES_PATH, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                return True
        return False
    except (json.JSONDecodeError, IOError):
        return False


def add_macro_theme(name: str, keywords: list, tag: str,
                    impact: int = 75, direction: str = "POSITIVE",
                    beneficiaries: list = None) -> str:
    """ìƒˆ ë§¤í¬ë¡œ í…Œë§ˆ ì¶”ê°€, theme_id ë°˜í™˜"""
    theme_id = tag + "_" + datetime.now().strftime("%Y%m%d")

    if MACRO_THEMES_PATH.exists():
        with open(MACRO_THEMES_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
    else:
        data = {"_meta": {"description": "ë§¤í¬ë¡œ í…Œë§ˆ ì‹œë‚˜ë¦¬ì˜¤", "updated_at": "", "usage": "ACTIVEë§Œ merge"}, "themes": []}

    new_theme = {
        "id": theme_id,
        "name": name,
        "status": "ACTIVE",
        "created": datetime.now().strftime("%Y-%m-%d"),
        "keywords": keywords,
        "impact": impact,
        "direction": direction,
        "tag": tag,
        "beneficiaries": beneficiaries or [],
    }
    data["themes"].append(new_theme)
    data["_meta"]["updated_at"] = datetime.now().strftime("%Y-%m-%d")

    with open(MACRO_THEMES_PATH, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return theme_id


def remove_macro_theme(theme_id: str) -> bool:
    """í…Œë§ˆ ì‚­ì œ"""
    if not MACRO_THEMES_PATH.exists():
        return False
    try:
        with open(MACRO_THEMES_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
        before = len(data.get("themes", []))
        data["themes"] = [t for t in data.get("themes", []) if t.get("id") != theme_id]
        if len(data["themes"]) == before:
            return False
        data["_meta"]["updated_at"] = datetime.now().strftime("%Y-%m-%d")
        with open(MACRO_THEMES_PATH, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except (json.JSONDecodeError, IOError):
        return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  DART ê³µì‹œ ìŠ¤ìº”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def fetch_dart_disclosures(days_back: int = 3) -> list:
    """DART OpenAPIì—ì„œ ìµœê·¼ ê³µì‹œ ìˆ˜ì§‘

    Returns: [{corp_name, ticker, report_nm, rcept_dt, event_type, impact, direction}]
    """
    api_key = os.getenv("DART_API_KEY", "")
    if not api_key:
        logger.info("DART_API_KEY ë¯¸ì„¤ì • â€” ê³µì‹œ ìŠ¤ìº” ê±´ë„ˆëœ€")
        return []

    end_date = datetime.now().strftime("%Y%m%d")
    start_date = (datetime.now() - timedelta(days=days_back)).strftime("%Y%m%d")

    url = "https://opendart.fss.or.kr/api/list.json"
    all_disclosures = []

    for page in range(1, 4):  # ìµœëŒ€ 3í˜ì´ì§€
        params = {
            "crtfc_key": api_key,
            "bgn_de": start_date,
            "end_de": end_date,
            "page_no": page,
            "page_count": 100,
            "sort": "date",
            "sort_mth": "desc",
        }

        try:
            resp = requests.get(url, params=params, timeout=10)
            data = resp.json()
            if data.get("status") != "000":
                break

            items = data.get("list", [])
            if not items:
                break

            for item in items:
                report_nm = item.get("report_nm", "")
                classified = _classify_event(report_nm)

                if classified:
                    all_disclosures.append({
                        "corp_name": item.get("corp_name", ""),
                        "ticker": item.get("stock_code", ""),
                        "report_nm": report_nm,
                        "rcept_dt": item.get("rcept_dt", ""),
                        "event_type": classified["event_type"],
                        "impact": classified["impact"],
                        "direction": classified["direction"],
                        "source": "DART",
                    })

            time.sleep(0.3)

        except Exception as e:
            logger.error(f"DART API ì˜¤ë¥˜: {e}")
            break

    logger.info(f"DART ê³µì‹œ: {len(all_disclosures)}ê±´ ê°ì§€")
    return all_disclosures


def _classify_event(report_title: str) -> Optional[dict]:
    """ê³µì‹œ ì œëª© â†’ ì´ë²¤íŠ¸ ë¶„ë¥˜"""
    for keywords, event_type, impact, direction in EVENT_RULES:
        for kw in keywords:
            if kw in report_title:
                return {
                    "event_type": event_type,
                    "impact": impact,
                    "direction": direction,
                }
    return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ë„¤ì´ë²„ ë‰´ìŠ¤ í…Œë§ˆ ìŠ¤ìº”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def scan_naver_news() -> list:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ 10ëŒ€ í…Œë§ˆ í‚¤ì›Œë“œ ìŠ¤ìº”

    Returns: [{theme, keyword, news_count, impact, direction, tag, source}]
    """
    detected = []
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }

    for theme_name, theme_info in THEME_KEYWORDS.items():
        for keyword in theme_info["keywords"]:
            try:
                url = "https://search.naver.com/search.naver"
                params = {
                    "where": "news",
                    "query": keyword,
                    "sort": "1",   # ìµœì‹ ìˆœ
                    "pd": "4",     # 1ì£¼ì¼
                    "start": "1",
                }

                resp = requests.get(url, params=params, headers=headers, timeout=8)
                if resp.status_code != 200:
                    continue

                # ë‰´ìŠ¤ ê±´ìˆ˜ ì¶”ì¶œ (ê°„ë‹¨í•œ ì •ê·œì‹)
                count_match = re.search(r'ì•½ ([\d,]+)ê±´', resp.text)
                if not count_match:
                    count_match = re.search(r'([\d,]+)ê±´', resp.text)
                news_count = int(count_match.group(1).replace(",", "")) if count_match else 0

                # ìµœì†Œ 3ê±´ ì´ìƒì´ë©´ í…Œë§ˆ í™œì„±
                if news_count >= 3:
                    detected.append({
                        "theme": theme_name,
                        "keyword": keyword,
                        "news_count": news_count,
                        "impact": theme_info["impact"],
                        "direction": theme_info["direction"],
                        "tag": theme_info["tag"],
                        "source": "NAVER_NEWS",
                        "date": datetime.now().strftime("%Y%m%d"),
                    })
                    break  # í…Œë§ˆë‹¹ 1ê°œ í‚¤ì›Œë“œë§Œ

                time.sleep(0.5)

            except Exception as e:
                logger.warning(f"ë‰´ìŠ¤ ìŠ¤ìº” ì‹¤íŒ¨ ({keyword}): {e}")
                continue

    logger.info(f"ë„¤ì´ë²„ ë‰´ìŠ¤: {len(detected)}ê°œ í…Œë§ˆ ê°ì§€")
    return detected


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ìˆ˜í˜œì£¼ ë§¤ì¹­
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def match_beneficiaries(events: list) -> list:
    """ì´ë²¤íŠ¸ â†’ ìˆ˜í˜œì£¼ ë§¤ì¹­ & ìŠ¤ì½”ì–´ ì§‘ê³„

    Returns: [{ticker, name, total_score, direction, events, metric}] ì •ë ¬ë¨
    """
    # tickerë³„ ì§‘ê³„
    ticker_data = {}  # ticker â†’ {name, scores[], events[], directions[]}

    for evt in events:
        if evt["source"] == "DART" and evt.get("ticker"):
            # DART ì§ì ‘ ìˆ˜í˜œ
            ticker = evt["ticker"]
            if ticker not in ticker_data:
                ticker_data[ticker] = {
                    "name": evt.get("corp_name", ticker),
                    "scores": [],
                    "events": [],
                    "directions": [],
                    "metric": "",
                }
            ticker_data[ticker]["scores"].append(evt["impact"])
            ticker_data[ticker]["events"].append(f'{evt["event_type"]}')
            ticker_data[ticker]["directions"].append(evt["direction"])

        elif evt["source"] == "NAVER_NEWS":
            # ë‰´ìŠ¤ ê°„ì ‘ ìˆ˜í˜œ â†’ BENEFICIARY_DB ë§¤ì¹­
            tag = evt.get("tag", "")
            beneficiaries = BENEFICIARY_DB.get(tag, [])
            for ticker, name, relevance, metric in beneficiaries:
                score = evt["impact"] * relevance / 100
                if ticker not in ticker_data:
                    ticker_data[ticker] = {
                        "name": name,
                        "scores": [],
                        "events": [],
                        "directions": [],
                        "metric": metric,
                    }
                ticker_data[ticker]["scores"].append(score)
                ticker_data[ticker]["events"].append(f'THEME:{evt["theme"]}')
                ticker_data[ticker]["directions"].append(evt["direction"])
                if not ticker_data[ticker]["metric"]:
                    ticker_data[ticker]["metric"] = metric

    # ì§‘ê³„
    results = []
    for ticker, data in ticker_data.items():
        total = sum(data["scores"])
        dirs = set(data["directions"])
        if "POSITIVE" in dirs and "NEGATIVE" in dirs:
            direction = "MIXED"
        elif "NEGATIVE" in dirs:
            direction = "NEGATIVE"
        elif "POSITIVE" in dirs:
            direction = "POSITIVE"
        else:
            direction = "NEUTRAL"

        results.append({
            "ticker": ticker,
            "name": data["name"],
            "total_score": round(total, 1),
            "direction": direction,
            "events": list(set(data["events"])),
            "metric": data["metric"],
        })

    results.sort(key=lambda x: -x["total_score"])
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ë©”ì¸ ìŠ¤ìº” + ì €ì¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_event_scan(scan_dart: bool = True, scan_news: bool = True) -> dict:
    """ì´ë²¤íŠ¸ ìŠ¤ìº” ì‹¤í–‰

    Returns: {scanned_at, events[], beneficiaries[]}
    """
    print(f"\nğŸ›°  ì´ë²¤íŠ¸ ê°ì§€ê¸°")
    print(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    print("=" * 50)

    # 0. ë§¤í¬ë¡œ í…Œë§ˆ ë™ì  ë¡œë“œ
    merged = load_macro_themes()
    if merged:
        print(f"  ë§¤í¬ë¡œ í…Œë§ˆ {merged}ê°œ ë¡œë“œ (ACTIVE)")

    all_events = []

    # 1. DART ê³µì‹œ
    if scan_dart:
        print("\n[1] DART ê³µì‹œ ìŠ¤ìº”...")
        dart_events = fetch_dart_disclosures(days_back=3)
        all_events.extend(dart_events)
        for evt in dart_events:
            icon = {"POSITIVE": "+", "NEGATIVE": "-", "NEUTRAL": "~"}.get(evt["direction"], "?")
            print(f"  [{icon}] {evt['corp_name']} â€” {evt['event_type']} ({evt['impact']})")

    # 2. ë„¤ì´ë²„ ë‰´ìŠ¤
    if scan_news:
        print("\n[2] ë„¤ì´ë²„ ë‰´ìŠ¤ í…Œë§ˆ ìŠ¤ìº”...")
        news_events = scan_naver_news()
        all_events.extend(news_events)
        for evt in news_events:
            icon = {"POSITIVE": "+", "NEGATIVE": "-"}.get(evt["direction"], "~")
            print(f"  [{icon}] {evt['theme']} â€” '{evt['keyword']}' ({evt['news_count']}ê±´)")

    # 3. ìˆ˜í˜œì£¼ ë§¤ì¹­
    print(f"\n[3] ìˆ˜í˜œì£¼ ë§¤ì¹­...")
    beneficiaries = match_beneficiaries(all_events)

    print(f"  ì´ë²¤íŠ¸: {len(all_events)}ê±´ | ìˆ˜í˜œì£¼: {len(beneficiaries)}ì¢…ëª©")

    if beneficiaries:
        print(f"\n  â”â” ìˆ˜í˜œì£¼ TOP 10 â”â”")
        for i, b in enumerate(beneficiaries[:10], 1):
            icon = {"POSITIVE": "+", "NEGATIVE": "-", "MIXED": "~"}.get(b["direction"], "?")
            print(f"  {i:>2}. [{icon}] {b['name']}({b['ticker']}) â€” {b['total_score']:.0f}ì  | {', '.join(b['events'])}")

    # ì €ì¥
    result = {
        "scanned_at": datetime.now().isoformat(),
        "total_events": len(all_events),
        "events": all_events,
        "beneficiaries": beneficiaries,
    }

    DATA_DIR.mkdir(parents=True, exist_ok=True)
    event_path = DATA_DIR / "events.json"
    with open(event_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"\n  ì €ì¥: {event_path}")

    return result


def format_event_report(result: dict) -> str:
    """í…”ë ˆê·¸ë¨ìš© ë¦¬í¬íŠ¸ í¬ë§·"""
    lines = []
    lines.append("ğŸ›° ì´ë²¤íŠ¸ ê°ì§€ê¸° ë¦¬í¬íŠ¸")
    lines.append(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

    # DART ê³µì‹œ
    dart = [e for e in result["events"] if e["source"] == "DART"]
    if dart:
        lines.append(f"\nğŸ“‹ DART ê³µì‹œ ({len(dart)}ê±´)")
        for e in dart[:5]:
            icon = {"POSITIVE": "ğŸŸ¢", "NEGATIVE": "ğŸ”´", "NEUTRAL": "ğŸŸ¡"}.get(e["direction"], "âšª")
            lines.append(f"  {icon} {e['corp_name']} â€” {e['event_type']}")

    # í…Œë§ˆ ë‰´ìŠ¤
    news = [e for e in result["events"] if e["source"] == "NAVER_NEWS"]
    if news:
        lines.append(f"\nğŸ“° í…Œë§ˆ ë‰´ìŠ¤ ({len(news)}ê°œ)")
        for e in news:
            icon = {"POSITIVE": "ğŸŸ¢", "NEGATIVE": "ğŸ”´"}.get(e["direction"], "ğŸŸ¡")
            lines.append(f"  {icon} {e['theme']} â€” '{e['keyword']}' ({e['news_count']}ê±´)")

    # ìˆ˜í˜œì£¼
    bens = result.get("beneficiaries", [])
    if bens:
        lines.append(f"\nğŸ¯ ìˆ˜í˜œì£¼ TOP 5")
        for i, b in enumerate(bens[:5], 1):
            icon = {"POSITIVE": "ğŸŸ¢", "NEGATIVE": "ğŸ”´", "MIXED": "ğŸŸ¡"}.get(b["direction"], "âšª")
            events_str = ", ".join(b["events"][:2])
            lines.append(f"  {i}. {icon} {b['name']}({b['ticker']}) â€” {b['total_score']:.0f}ì ")
            lines.append(f"     {events_str}")

    lines.append("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    return "\n".join(lines)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
    logging.basicConfig(level=logging.WARNING)

    from dotenv import load_dotenv
    load_dotenv(Path(__file__).resolve().parent.parent.parent / ".env")

    import argparse
    parser = argparse.ArgumentParser(description="ì´ë²¤íŠ¸ ê°ì§€ê¸°")
    parser.add_argument("--dart-only", action="store_true", help="DARTë§Œ")
    parser.add_argument("--news-only", action="store_true", help="ë‰´ìŠ¤ë§Œ")
    parser.add_argument("--telegram", action="store_true", help="í…”ë ˆê·¸ë¨ ì „ì†¡")
    args = parser.parse_args()

    scan_dart = not args.news_only
    scan_news = not args.dart_only

    result = run_event_scan(scan_dart=scan_dart, scan_news=scan_news)

    if args.telegram and result["beneficiaries"]:
        try:
            from bot.telegram_bot import send_message
            msg = format_event_report(result)
            send_message(msg)
            print("\n  í…”ë ˆê·¸ë¨ ì „ì†¡ ì™„ë£Œ")
        except Exception as e:
            print(f"\n  í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")
